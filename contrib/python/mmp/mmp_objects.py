###################################################################
""" Summary: Class and Methods to get matched moleular pairs from smiles

About: The class is an implementation of Hussain & Rea's approach to generating
Matched Molecular Pairs (J Chem Inf Modea 2013, 50, 339-348) adapted 
for the Lilly Dicer fragmentation code.  Input smiles are stored,
all dicer fragments are stored and a new Dictonary object created to 
store the matched pairs.  The data object should not be read directly
for double cuts due to the way the cut/attachment points are labelled 
in dicer. (JAL)

Example usage:
    
    my_mmp_object = MMPObjectClass(my_logger)
    my_mmp_object.build_from_dicer(smi_fi, cut_type, filter_type)
    my_mmp_object.print_to_file(out_fi, out_fmt, cut_type)

Warnings: This class assumes the input smiles are already salt stripped
and that their identifiers and convertible to a valid integer value. Input
smiles of the type "c1ccccc1[N+].[Cl-] CHEMBL9876" will fail for both reasons
"""
###################################################################

import re
import logging
import sys

import unittest
import tempfile
import copy

from mmp.mmp_math_functions import cantor, inv_cantor
import mmp.mmp_dicer_functions as dicer


class MMPObjectClass(object):

    """Class implements objects nad methods for MMP generation using Dicer fragmentation output
    Instantiation of the object requires a valid python logger object to be
    passed in as a parameter, even if the logger is switched off.
    
    Example usage:
        mmplogger = logging.getLogger('lillymolfile_logger')
        logging.disable(logging.CRITICAL)
        my_mmp_object = MMPObjectClass(mmplogger)

    Due to the large number of repeat smiles generated by dicer fragmentation,
    normalisation is applied to the final single and double cut matched pairs
    objects.  The actual MMP data objects single_pairs_dict and double_pairs_dict
    simply contain numerical id's for ever smiles. The smiles are stored in
    refsmi_dict
    """
    def __init__(self, logger_object):

        self.logger = logger_object
        if len(logging.Logger.manager.loggerDict) < 1:
            # exit with system status 1 and custom error
            sys.exit("Invalid or no logger object passed to MMPObjectClass.  Please create \
                    and pass a logger and set to use logging.disable if you don't want logging")

        # remains as dict smi => id
        # but also do reverse insert id => smi
        # keep refsmi_id at object level as may use methods involving this id multiple times
        self.refsmi_id = 0
        self.refsmi_dict = {}

        # Don't want to store input SMI in refsmi_dict in case we get a
        # key clash with the numbers used in the refsmi_dict index
        # generated by the cantor pairing, therefore use separate dict
        self.mol_smi_dict = {}

        # dict to store the attachment points
        self.refattach_id = 0
        self.refattach_dict = {}

        # become dict of dicts
        self.single_pairs_dict = {}
        self.double_pairs_dict = {}

        # some of the iterators attached to this method work on the entire object or on a second custom dict
        # but in order to accept a second custom dict it needs to look the same as the base objects i.e.:
        # self.single_pairs_dict and self.double_pairs_dict
        # Example useage include mmp_predict where we take mols/ctx from single_pairs_comparison_dict and 
        # get a predicted delta from the pair in self.single_pairs_dict
        self.single_pairs_comparison_dict = {}
        self.double_pairs_comparison_dict = {}

        # 02/16 Added this for MMS work to avoid exhaustive enumeration of MMS
        # Becomes a dict of frag1 => { ctx_1 = None,
        #                              ctx_2 = None }
        #                   frag2 => { ctx_3 = None }
        # so we can quickly find which ctx base MMS we need to enumerate via this lookup table
        # and can then just enumerate a subset of MMS from self.single_pairs_dict not all
        self.frag_ctx_lookup_sgl = {}
        self.frag_ctx_lookup_dbl = {}

    def clean_out_data(self):
        """Method to clean out all objects in class"""

        # just clean out all the dicts
        self.refsmi_dict.clear()
        self.single_pairs_dict.clear()
        self.double_pairs_dict.clear()
        #
        self.single_pairs_comparison_dict.clear()
        self.double_pairs_comparison_dict.clear()

    def scan_input_smiles(self, smi_fi, injest=False, fail_chirals=False):
        """
        Dicer currently finishes with an exit code of zero, even if it fails and bombs half way through. This means the
        MMP code can complete with results but has missed many pairs due to failed fragmentation, this injects a
        pre-check into the process to remove/drop smiles likely to fail dicer BEFORE they get parsed to dicer or just
        crash out with an error code.
        """
        with open(smi_fi, "r") as input_smifi:

            self.logger.info('Beginning pre-scan of input smiles file')

            line_num = 0
            for line in input_smifi:

                line_num += 1
                line_list = line.split()

                # check it's valid smiles file format which is "smiles\sid"
                if len(line_list) != 2:
                    # random exit code of 4
                    sys.exit("Failed to parse smiles from line %s of file %s" %
                             (line_num, smi_fi))

                # Is the smiles_id numeric?
                try:
                    smiles_id = int(line_list[1])
                except:
                    sys.exit("Failed smiles parser as non-numeric id on line %s, id %s of file %s" %
                             (line_num, smiles_id, smi_fi))

                smiles = line_list[0]

                if len(smiles) < 2:
                    sys.exit("Failed smiles parser as tiny smi size on line %s, id %s of file %s" %
                             (line_num, smiles_id, smi_fi))

                if "." in smiles:
                    sys.exit("Failed smiles parser as salt on line %s, id %s\nfilename: %s" %
                             (line_num, smiles_id, smi_fi))

                if "[1" in smiles or "[2" in smiles:
                    sys.exit("Failed smiles parser as smiles on line %s has isomeric label [1 or [2 %s" %
                             (line_num, smi_fi))

                if fail_chirals:
                    if "@" in smiles:
                        sys.exit("Failed smiles parser as smiles on line %s contains chiral flags @: %s" %
                                 (line_num, smi_fi))

                if injest:
                    # add to the mol_smi_dict as mol_id => smiles
                    self.mol_smi_dict[smiles_id] = line_list[0]

            self.logger.info('Completed pre-scan of input smiles file with no errors')

    def build_from_dicer(self, smi_fi, cut_type, filter_type, threshold=0.50001, use_comparison_dict=False,
                         add_frag_ctx_map=False):
        """Method to take an input smiles file, fragment each entry with dicer, then read
        the dicer output back into the MMP data structure. The data structures produced
        by this method should not be accessed directly. The following parameters are 
        mandatory:
        
        smi_fi:
          The user specified smiles file
        
        cut_type:
          Specifies the type of fragmentation required.  Allowed values are SINGLE, 
          DOUBLE or BOTH.  Currently this class does not support anything greater than 
          double cut fragmentation
                 
        filter_type:
          Optional filtering can be applied to remove rings or non-rings from any of 
          the matched pairs generated.
          REMOVE_NONRINGS, REMOVE_RINGS where NONE will results in all dicer output 
          being used/stored.  Filtering is achieved using the regular expression '[^H\[]\d'

        Example usage, all matched pairs single and double cut fragmentation:
            my_mmp_object.build_from_dicer('mysmiles.smi', 'BOTH', 'NONE')

        Example usage, Terminal ring replacements:
            my_mmp_object.build_from_dicer('mysmiles.smi', 'SINGLE', 'REMOVE_NONRINGS')

        Example usage, non-ring linker matched pairs / replacements:
            my_mmp_object.build_from_dicer('mysmiles.smi', 'DOUBLE', 'REMOVE_RINGS')

        180515 - Added parameter use_comparison_dict in order to hijack method and allow
        us to reuse code in building an additional MMP data structure for use in later algorithms
        such as mmp_predict, this writes data to an alternate 'comparison' dict of same structure

        260516 - Surfaced maxff setting as threshold param.
        Use of threshold default 0.50001 ensures >50.001% of mol remains as context.  Larger values
        will remove smaller fragments and a value of 0.7 will retain 70% of the mol as context
        """
        # smi_fi and cut_type are passed through to build_mmpdicer_cmd()
        self.logger.debug("Dicer threshold: %s" % threshold)

        # see comments on below iterator_single_pairs_dict
        if use_comparison_dict is False:
            query_dict_single = self.single_pairs_dict
            query_dict_double = self.double_pairs_dict

        elif use_comparison_dict is True:
            query_dict_single = self.single_pairs_comparison_dict
            query_dict_double = self.double_pairs_comparison_dict

        else:
            self.logger.debug("Invalid parameter for method, use_ctx_lookup_dict must be True or False")
            sys.exit("Invalid parameter for method, use_ctx_lookup_dict must be True or False")

        # * Check filter_type, convert to int
        # * Regex works by finding all examples of xN where x is an atom or ')' and N is a number/int
        # For example c1 / n2 / )1 which are all ring close/open smiles.  We need to exclude things like
        # ]1 and 12 which give false matches against isomerically labelled groups.
        # Full details: [^H\d\[]\d pattern group [] plus digit \d, inside pattern group ^H^\d\[ means
        # ^ means NOT.. H, digit \d or escaped [
        #
        if filter_type == 'REMOVE_NONRINGS':
            filter_id = 2
            regex_rings = re.compile(r'[^H\d\[]\d')
        elif filter_type == 'REMOVE_RINGS':
            filter_id = 3
            regex_rings = re.compile(r'[^H\d\[]\d')
        else:
            filter_id = 1
        
        # check cut_type, convert to int
        if cut_type.upper() == 'DOUBLE':
            # confusing but faster later
            cut_type_id = 3
        elif cut_type.upper() == 'BOTH':
            # confusing but faster later
            cut_type_id = 2
        elif cut_type.upper() == 'SINGLE':
            cut_type_id = 1
        else:
            self.logger.warn('cut_type specification is incorrect, using single cut: %s' % cut_type.upper())
            cut_type_id = 1

        #
        ctx1_id = 0
        ctx2_id = 0
        frag_id = 0

        dupe_frags_s = 0
        dupe_frags_d = 0
        
        # regex to find contexts that have a fragmentation point label of '1'
        regex_context1 = re.compile(r'\[1\w{1,3}\]')

        for num_cuts, mol_id, ctx_orig, frag, fattach, cattach in dicer.execute_dicer(smi_fi, cut_type, threshold,
                                                                                      self.logger):
            
            # use continue for filter conditions, some say continue is not nice
            if filter_id > 1:
                if regex_rings.search(frag) is None:
                    rings = 0
                else:
                    rings = 1
                if filter_id == 3 and rings > 0:
                    continue
                elif filter_id == 2 and rings == 0:
                    continue

            # add frag to smi dict or get id if exists
            # self.refsmi_dict [a_smiles_string] => an_arbitrary_uniqueid
            if frag in self.refsmi_dict:
                frag_id = self.refsmi_dict[frag]
            else:
                self.refsmi_id += 1
                self.refsmi_dict[frag] = self.refsmi_id
                self.refsmi_dict[self.refsmi_id] = frag
                frag_id = self.refsmi_id
                self.logger.debug('Got new fragment: %s with id %s' % (frag, self.refsmi_id))

            # add attachment points to self.refattach_dict both ways to allow for
            # reverse lookup: [attachment point string] = random_id and reverse
            if fattach in self.refattach_dict:
                fattach_id = self.refattach_dict[fattach]
            else:
                self.refattach_id += 1
                self.refattach_dict[fattach] = self.refattach_id
                self.refattach_dict[self.refattach_id] = fattach
                fattach_id = self.refattach_id
                self.logger.debug('Got new Attachment point label: %s with id %s' % (fattach, fattach_id))

            if cattach in self.refattach_dict:
                cattach_id = self.refattach_dict[cattach]
            else:
                self.refattach_id += 1
                self.refattach_dict[cattach] = self.refattach_id
                self.refattach_dict[self.refattach_id] = cattach
                cattach_id = self.refattach_id
                self.logger.debug('Got new Attachment point label: %s with id %s' % (cattach, cattach_id))

            if num_cuts == 1 and cut_type_id <= 2:
                
                # does the context already have an unique id? if not get one and add to self.refsmi_dict
                if ctx_orig in self.refsmi_dict:
                    ctx1_id = self.refsmi_dict[ctx_orig]
                else:
                    self.refsmi_id += 1
                    self.refsmi_dict[ctx_orig] = self.refsmi_id
                    self.refsmi_dict[self.refsmi_id] = ctx_orig
                    ctx1_id = self.refsmi_id
                    self.logger.debug('Got new single cut ctx smi: %s with id %s' % (ctx_orig, self.refsmi_id))
                
                # now create molid_ctx1id_id which is a unique combination of the mol_id paired with a valid frag_id
                # for that given mol_id.
                # we need to store both, as they are different fragmentations, keying a dict by mol_id would overwrite
                # values so we create unique molid + fragid combination (** see matching comments below)
                molid_fragid_uid = cantor(mol_id, frag_id)
                
                #
                # add to the MMP data structure
                if ctx1_id in query_dict_single:

                    # check to remove dupes occuring from groups like CF3 that give 3 x C-F fragmentation
                    if molid_fragid_uid in query_dict_single[ctx1_id]:
                        dupe_frags_s = dupe_frags_s + 1
                    else:
                        self.logger.debug('Add to query dict (ctx_id, mol_id (as molid_fragid_uid), '
                                          'frag_id): %s, %s, %s, %s' % (ctx1_id, mol_id, molid_fragid_uid, frag_id))
                        query_dict_single[ctx1_id][molid_fragid_uid] = (fattach_id, cattach_id)

                else:
                    # create new entry in single cut MMP dict
                    # builds data structure of:
                    #     dict_single[ctx1]  => { mol1_frag1_id => frag1 }
                    #     dict_single[ctx2]  => { mol1_frag2_id => frag2 }
                    #     dict_single[ctx3]  => { mol1_frag3_id => frag3 }
                    # As you add new mols you get something like:
                    #     dict_single[ctx1]  => { mol1_frag1_id => frag1,  mol2_frag4_id => frag4, }
                    #     dict_single[ctx2]  => { mol1_frag2_id => frag2,  mol2_frag5_id => frag5, }
                    #     dict_single[ctx3]  => { mol1_frag3_id => frag3 }
                    #     dict_single[ctx4]  => { mol2_frag6_id => frag6 }
                    query_dict_single[ctx1_id] = {}
                    self.logger.debug('Add to query dict (ctx_id, mol_id (as molid_fragid_uid), '
                                      'frag_id): %s, %s, %s, %s' % (ctx1_id, mol_id, molid_fragid_uid, frag_id))
                    query_dict_single[ctx1_id][molid_fragid_uid] = (fattach_id, cattach_id)

                # 02/16
                # added in for Matched Series on-the-fly generation
                if add_frag_ctx_map:

                    if frag_id in self.frag_ctx_lookup_sgl:

                        # just add it, don't care if we overwrite
                        self.frag_ctx_lookup_sgl[frag_id].add(ctx1_id)

                    else:
                        self.frag_ctx_lookup_sgl[frag_id] = set()
                        self.frag_ctx_lookup_sgl[frag_id].add(ctx1_id)

            elif num_cuts == 2 and cut_type_id >= 2:
                
                # split up the fragments and fragment attachment points
                ctx_list = ctx_orig.split('.')
                ctx1_tmp = ctx_list[0]
                ctx2_tmp = ctx_list[1]
                
                # sort context, should not need to do this with latest dicer as enforces order [1xxxx . [2xxxx
                if regex_context1.search(ctx1_tmp) is not None:
                    ctx1 = ctx1_tmp
                    ctx2 = ctx2_tmp
                else:
                    ctx1 = ctx2_tmp
                    ctx2 = ctx1_tmp
                
                # normalise
                if ctx1 in self.refsmi_dict:
                    ctx1_id = self.refsmi_dict[ctx1]
                else:
                    self.refsmi_id += 1
                    self.refsmi_dict[ctx1] = self.refsmi_id
                    self.refsmi_dict[self.refsmi_id] = ctx1
                    ctx1_id = self.refsmi_id
                    self.logger.debug('Got new double cut ctx smi: %s with id %s' % (ctx1, self.refsmi_id))

                if ctx2 in self.refsmi_dict:
                    ctx2_id = self.refsmi_dict[ctx2]
                else:
                    self.refsmi_id += 1
                    self.refsmi_dict[ctx2] = self.refsmi_id
                    self.refsmi_dict[self.refsmi_id] = ctx2
                    ctx2_id = self.refsmi_id
                    self.logger.debug('Got new double cut ctx smi: %s with id %s' % (ctx2, self.refsmi_id))

                # combine to get unique id, this is simply for speed
                # cantor pairing function allows us to combine two unique id's to get a new single id
                # however, what's neat is that we can do a reverse cantor to get both original id's back again
                # so we get very fast hash lookup and smaller storage (single id instead of tuple of 2 id's)
                # Need to store this in numeric order to avoid misparsing dicer output
                if ctx1_id <= ctx2_id:
                    ctx12_id = cantor(ctx1_id, ctx2_id)
                else:
                    ctx12_id = cantor(ctx2_id, ctx1_id)
                
                molid_fragid_uid = cantor(mol_id, frag_id)

                if ctx12_id in query_dict_double:
                    # check to remove dupes occurring from groups like CF3
                    if molid_fragid_uid in query_dict_double[ctx12_id]:
                        dupe_frags_s += 1
                    else:
                        self.logger.debug('Add to Query dict Double cut dict (ctx12_id (ctx1_id, ctx2_id), '
                                          'molid_fragid_uid (mol_id, frag_id): %s, %s, %s, %s, %s, %s' %
                                          (ctx12_id, ctx1_id, ctx2_id, molid_fragid_uid, mol_id, frag_id))
                        query_dict_double[ctx12_id][molid_fragid_uid] = (fattach_id, cattach_id)
                else:
                    query_dict_double[ctx12_id] = {}
                    self.logger.debug('Add to Query dict Double cut dict (ctx12_id, ctx1_id, ctx2_id, '
                                      'molid_fragid_uid, mol_id, frag_id): %s, %s, %s, %s, %s, %s' %
                                      (ctx12_id, ctx1_id, ctx2_id, molid_fragid_uid, mol_id, frag_id))
                    query_dict_double[ctx12_id][molid_fragid_uid] = (fattach_id, cattach_id)

                # 02/16
                # added in for Matched Series on-the-fly generation
                if add_frag_ctx_map:

                    if frag_id in self.frag_ctx_lookup_dbl:

                        # just add it, don't care if we overwrite
                        self.frag_ctx_lookup_dbl[frag_id].add(ctx12_id)

                    else:
                        self.frag_ctx_lookup_dbl[frag_id] = set()
                        self.frag_ctx_lookup_dbl[frag_id].add(ctx12_id)

            # catch severe fails
            else:
                self.logger.debug('Filtered out line with %d cuts' % num_cuts)
        
            self.logger.debug('mem_trace refsmi_dict entries entries: %s, mem usage: %s' %
                              (len(self.refsmi_dict), sys.getsizeof(self.refsmi_dict)/1000))
            self.logger.debug('mem_trace query_dict entries: %s, mem usage: %s' %
                              (len(query_dict_single), sys.getsizeof(query_dict_single)/1000))
            self.logger.debug('mem_trace double_pairs_dict entries: %s, mem usage: %s' %
                              (len(query_dict_double), sys.getsizeof(query_dict_double)/1000))

        # wrap up
        self.logger.info('Done reading dicer output into single and double pair dicts')
        
        self.logger.info('mem_trace refsmi_dict entries: %s, mem usage: %s' %
                         (len(self.refsmi_dict), sys.getsizeof(self.refsmi_dict)/1000))

        self.logger.info('mem_trace query_dict single entries: %s, mem usage: %s' %
                         (len(query_dict_single), sys.getsizeof(query_dict_single)/1000))
        self.logger.info('mem_trace query_dict double entries: %s, mem usage: %s' %
                         (len(query_dict_double), sys.getsizeof(query_dict_double)/1000))
        self.logger.info('Removed %d and %d duplicate fragmentation patterns from single_pairs_dict'
                         ' & double_pairs_dict' % (dupe_frags_s, dupe_frags_d))

    def iterator_single_pairs_dict_numeric(self, inc_attachpt=False, use_comparison_dict=False):
        """ Method to iterate over Single Cut Dictionary structure and yield
        numeric values of pairs to be used programmatically in other new data
        structure such as with H enrichment algorithm or graph building"""
        
        # see comments on below iterator_single_pairs_dict
        if use_comparison_dict is False:
            query_dict = self.single_pairs_dict
            
        elif use_comparison_dict is True:
            query_dict = self.single_pairs_comparison_dict

        else:
            self.logger.debug("Invalid parameter for method, use_ctx_lookup_dict must be True or False")
            sys.exit("Invalid parameter for method, use_ctx_lookup_dict must be True or False")

        # structure of this iterator follows iterator_single_pairs_dict
        for ctx_id in query_dict:
            
            for molid_fragid_uid_L in query_dict[ctx_id]:
                molid_L, frag_id_L = inv_cantor(molid_fragid_uid_L)
                
                if ctx_id in self.single_pairs_dict:
                    for molid_fragid_uid_R in self.single_pairs_dict[ctx_id]:
                        molid_R, frag_id_R = inv_cantor(molid_fragid_uid_R)
                        
                        if molid_L != molid_R:

                            if frag_id_L != frag_id_R:

                                if inc_attachpt:

                                    # get attachment points:
                                    fattach_R = self.single_pairs_dict[ctx_id][molid_fragid_uid_R][0]
                                    cattach_R = self.single_pairs_dict[ctx_id][molid_fragid_uid_R][1]
                                    fattach_L = query_dict[ctx_id][molid_fragid_uid_L][0]
                                    cattach_L = query_dict[ctx_id][molid_fragid_uid_L][1]

                                    yield molid_L, molid_R, ctx_id, frag_id_L, frag_id_R, fattach_L, cattach_L, \
                                          fattach_R, cattach_R
                                
                                else:
                                    yield molid_L, molid_R, ctx_id, frag_id_L, frag_id_R

    def iterator_single_pairs_dict(self, use_comparison_dict=False):
        """ Method to iterate over Single Cut Dictionary structure and yield pairs """

        # hijack method with an alternate query dict and therefore search between SMI sets not just withing SMI sets
        if use_comparison_dict is False:
            query_dict = self.single_pairs_dict

        elif use_comparison_dict is True:
            # will use a restricted set of context's for pair lookup
            query_dict = self.single_pairs_comparison_dict
            
        else:
            # error
            self.logger.debug("Invalid parameter for method, use_ctx_lookup_dict must be True or False")
            sys.exit("Invalid parameter for method, use_ctx_lookup_dict must be True or False")

        self.logger.info('Iterating over single cut pairs dictionary')

        for ctx_id in query_dict:

            # pairs are already determined by the data structure, for example:
            #     dict_single[ctx1]  => { mol1_frag1_id => frag1,  mol2_frag4_id => frag4, }
            #     dict_single[ctx2]  => { mol1_frag2_id => frag2,  mol2_frag5_id => frag5, }
            #     dict_single[ctx3]  => { mol1_frag3_id => frag3 }
            #     dict_single[ctx4]  => { mol2_frag6_id => frag6 }
            # pairs exist where the context is the same, but the fragment differs
            # so for ctx2, we find a matched pair between mol1 and mol2 of 'frag1 -> frag5'
            ctx = self.refsmi_dict[ctx_id]
            
            for molid_fragid_uid_L in query_dict[ctx_id]:
                
                molid_L, frag_id_L = inv_cantor(molid_fragid_uid_L)
                frag_L = self.refsmi_dict[frag_id_L]
                
                if ctx_id in self.single_pairs_dict:
                    for molid_fragid_uid_R in self.single_pairs_dict[ctx_id]:
                        molid_R, frag_id_R = inv_cantor(molid_fragid_uid_R)
                        
                        # filter out self matches
                        if molid_L != molid_R:
                            
                            # filter out (non) pair change where frag is identical in each mol
                            if frag_id_L != frag_id_R:
                                frag_R = self.refsmi_dict[frag_id_R]
                                
                                # finally get the attachment point info back from the numeric id's
                                fattach_str_R = self.refattach_dict[self.single_pairs_dict[ctx_id][molid_fragid_uid_R][0]]
                                cattach_str_R = self.refattach_dict[self.single_pairs_dict[ctx_id][molid_fragid_uid_R][1]]
                                fattach_str_L = self.refattach_dict[query_dict[ctx_id][molid_fragid_uid_L][0]]
                                cattach_str_L = self.refattach_dict[query_dict[ctx_id][molid_fragid_uid_L][1]]

                                yield molid_L, molid_R, ctx, frag_L, frag_R, fattach_str_L, cattach_str_L, \
                                      fattach_str_R, cattach_str_R

    def iterator_double_pairs_dict_numeric(self, inc_attachpt=False, use_comparison_dict=False):
        """Method to iterate over Double Cut Dictionary structure and yield pairs as numeric ID's. This method uses more
        memory than the non-numeric iterator as it inserts new smi into the smi_dict representing flipped double cut
        smi, and is consequently slower if big dict resize. It is not needed for simple MMP generation but was written
        for more complex methods that sit above the MMP code such as the MCSS generation code that re-stores MMPs, hence
        the need for numeric ID's for mem efficiency. Also, the iterator will return an additional numeric value to the
        single cut one as there are two different numeric id's returned for a context that cannot be stored / returned
        together (whereas a smiles can as dot delimited).
        """

        # as per single cuts comment
        if use_comparison_dict is False:
            # memory pointer!
            query_dict = self.double_pairs_dict

        elif use_comparison_dict is True:
            # will use a restricted set of context's for pair lookup
            query_dict = self.double_pairs_comparison_dict

        else:
            # error
            self.logger.debug("Invalid parameter for method, use_ctx_lookup_dict must be True or False")
            sys.exit("Invalid parameter for method, use_ctx_lookup_dict must be True or False")

        self.logger.info('Inverting refattach_dict')

        # unfortunately need to invert self.refattach_dict
        for key, val in self.refattach_dict.items():
            if val not in self.refattach_dict:
                self.refattach_dict[val] = key
        self.logger.info('done inverting refattach_dict')

        self.logger.info('Iterating over double cut pairs dictionary')

        # regex to find contexts that have a fragmentation point label of '1'
        regex_context1 = re.compile(r'\[1\w{1,3}\]')

        def convert_smi_to_id(smiles):

            if smiles in self.refsmi_dict:
                smiles_id = self.refsmi_dict[smiles]
            else:
                self.refsmi_id += 1
                self.refsmi_dict[smiles] = self.refsmi_id
                self.refsmi_dict[self.refsmi_id] = smiles
                smiles_id = self.refsmi_id

            return smiles_id

        def convert_attachsmi_to_id(attach):

            if attach in self.refattach_dict:
                attach_id = self.refattach_dict[attach]
            else:
                self.refattach_id += 1
                attach_id = self.refattach_id
                self.refattach_dict[attach] = self.refattach_id
                self.refattach_dict[self.refattach_id] = attach

            return attach_id

        for ctxm_id in query_dict:

            # pairs are found in exactly the same way as single cuts

            # first deconvolute the context ids so we can get back the smiles
            ctx1_id_tmp, ctx2_id_tmp = inv_cantor(ctxm_id)
            ctx1_tmp = self.refsmi_dict[ctx1_id_tmp]
            ctx2_tmp = self.refsmi_dict[ctx2_id_tmp]

            # not sure if I need the regex anymore with the new dicer canonicalisation
            if regex_context1.search(ctx1_tmp) is not None:
                # got [1 so keep
                ctx1_id = ctx1_id_tmp
                ctx1 = ctx1_tmp
                ctx2_id = ctx2_id_tmp
                ctx2 = ctx2_tmp
            else:
                ctx1_id = ctx2_id_tmp
                ctx1 = ctx2_tmp
                ctx2_id = ctx1_id_tmp
                ctx2 = ctx1_tmp

            ctx1_f = ctx1
            ctx2_f = ctx2

            ctx1_f = ctx1_f.replace("[1", "[9").replace("[2", "[1").replace("[9", "[2")
            ctx2_f = ctx2_f.replace("[1", "[9").replace("[2", "[1").replace("[9", "[2")

            ctx1_f_id = convert_smi_to_id(ctx1_f)
            ctx2_f_id = convert_smi_to_id(ctx2_f)

            self.logger.debug('Got: %s, %s from %s' % (ctx1_id, ctx2_id, ctxm_id))
            self.logger.debug('which converts to context: %s, %s' % (ctx1, ctx2))

            # now find pairs
            for molid_fragid_uid_L in query_dict[ctxm_id]:
                molid_L, frag_id_L = inv_cantor(molid_fragid_uid_L)
                frag_L = self.refsmi_dict[frag_id_L]

                # check it exists in double_pairs_dict, because it might not if
                # we are comparing data from double_pairs_comparison_dict
                if ctxm_id in self.double_pairs_dict:

                    # flip it, as we need to reverse numbering
                    frag_L_f = frag_L
                    if '[12' not in frag_L:
                        frag_L_f = frag_L_f.replace("[1", "[9")
                        frag_L_f = frag_L_f.replace("[2", "[1")
                        frag_L_f = frag_L_f.replace("[9", "[2")

                        frag_L_f_id = convert_smi_to_id(frag_L_f)

                    else:
                        frag_L_f_id = frag_id_L

                    if inc_attachpt:
                        fattach_str_L_id = query_dict[ctxm_id][molid_fragid_uid_L][0]
                        cattach_str_L_id = query_dict[ctxm_id][molid_fragid_uid_L][1]
                        fattach_str_L = self.refattach_dict[fattach_str_L_id]
                        cattach_str_L = self.refattach_dict[cattach_str_L_id]

                        fattach_str_L_f = re.sub("\[(\d)(.*)\|(\d)(.*)", r"[\3\2|\1\4", fattach_str_L)
                        cattach_str_L_f = re.sub("\[(\d)(.*)\|(\d)(.*)", r"[\3\2|\1\4", cattach_str_L)

                        fattach_str_L_id_f = convert_attachsmi_to_id(fattach_str_L_f)
                        cattach_str_L_id_f = convert_attachsmi_to_id(cattach_str_L_f)

                    # now iterate over pairs
                    for molid_fragid_uid_R in self.double_pairs_dict[ctxm_id]:

                        molid_R, frag_id_R = inv_cantor(molid_fragid_uid_R)
                        # print "Working with molid_l=%s, molid_r=%s, ctx=%s, frag_L=%s, frag_r=%s" %
                        #    (molid_L, molid_R, ctx, frag_L, self.refsmi_dict[frag_id_R] )

                        if molid_L != molid_R:

                            frag_R = self.refsmi_dict[frag_id_R]
                            # need to remove pairs where the original smiles was identical for both molid
                            # which results in a pair with frag_l == frag_r and is not of interest
                            # this mostly occurs because we do not handle chirality
                            # this simple if string comparison statement is expensive and slows code down!
                            if frag_L != frag_R:

                                # At this point we have a pair!

                                # now flip the R
                                frag_R_f = frag_R
                                if '[12' not in frag_R:
                                    frag_R_f = frag_R_f.replace("[1", "[9")
                                    frag_R_f = frag_R_f.replace("[2", "[1")
                                    frag_R_f = frag_R_f.replace("[9", "[2")

                                    frag_R_f_id = convert_smi_to_id(frag_R_f)

                                else:
                                    frag_R_f_id = frag_id_R

                                # and flip attachment points
                                if inc_attachpt:

                                    # finally get the attachment point info back from the numeric id's
                                    fattach_str_R_id = self.double_pairs_dict[ctxm_id][molid_fragid_uid_R][0]
                                    cattach_str_R_id = self.double_pairs_dict[ctxm_id][molid_fragid_uid_R][1]
                                    fattach_str_R = self.refattach_dict[fattach_str_R_id]
                                    cattach_str_R = self.refattach_dict[cattach_str_R_id]

                                    # regex to flip the numbers in the attachment points
                                    fattach_str_R_f = re.sub("\[(\d)(.*)\|(\d)(.*)", r"[\3\2|\1\4", fattach_str_R)
                                    cattach_str_R_f = re.sub("\[(\d)(.*)\|(\d)(.*)", r"[\3\2|\1\4", cattach_str_R)

                                    #
                                    fattach_str_R_id_f = convert_attachsmi_to_id(fattach_str_R_f)
                                    cattach_str_R_id_f = convert_attachsmi_to_id(cattach_str_R_f)

                                    for count_ in range(2):
                                        if count_ == 0:
                                            # original with attachment point numbers
                                            yield molid_L, molid_R, ctx1_id, ctx2_id, frag_id_L, frag_id_R,\
                                                  fattach_str_L_id, cattach_str_L_id, fattach_str_R_id, cattach_str_R_id
                                        else:
                                            # reversed format
                                            yield molid_L, molid_R, ctx1_f_id, ctx2_f_id, frag_L_f_id, frag_R_f_id, \
                                                  fattach_str_L_id_f, cattach_str_L_id_f, fattach_str_R_id_f, \
                                                  cattach_str_R_id_f

                                else:
                                    for count_ in range(2):
                                        if count_ == 0:
                                            # original
                                            yield molid_L, molid_R, ctx1_id, ctx2_id, frag_id_L, frag_id_R
                                        else:
                                            # reversed
                                            yield molid_L, molid_R, ctx1_f_id, ctx2_f_id, frag_L_f_id, frag_R_f_id

    def __subiterator_double_pairs_dict(self, use_comparison_dict):
        """A hidden sub method used by iterator_double_pairs_dict() method 
        to iterate over Double Cut Dictionary structure and yield pairs"""

        # as per single cuts comment
        if use_comparison_dict is False:
            # memory pointer!
            query_dict = self.double_pairs_dict

        elif use_comparison_dict is True:
            # will use a restricted set of context's for pair lookup
            query_dict = self.double_pairs_comparison_dict

        else:
            # error
            self.logger.debug("Invalid parameter for method, use_ctx_lookup_dict must be True or False")
            sys.exit("Invalid parameter for method, use_ctx_lookup_dict must be True or False")

        self.logger.info('Iterating over double cut pairs dictionary')

        # regex to find contexts that have a fragmentation point label of '1'
        regex_context1 = re.compile(r'\[1\w{1,3}\]')

        for ctxm_id in query_dict:
            
            # pairs are found in exactly the same way as single cuts
            
            # first deconvolute the context ids so we can get back the smiles
            ctx1_id_tmp, ctx2_id_tmp = inv_cantor(ctxm_id)
            ctx1_tmp = self.refsmi_dict[ctx1_id_tmp]
            ctx2_tmp = self.refsmi_dict[ctx2_id_tmp]
            
            if regex_context1.search(ctx1_tmp) is not None:
                # got [1 so keep
                ctx1_id = ctx1_id_tmp
                ctx1 = ctx1_tmp
                ctx2_id = ctx2_id_tmp
                ctx2 = ctx2_tmp
            else:
                ctx1_id = ctx2_id_tmp
                ctx1 = ctx2_tmp
                ctx2_id = ctx1_id_tmp
                ctx2 = ctx1_tmp

            ctx = ctx1 + "." + ctx2

            self.logger.debug('Got: %s, %s from %s' % (ctx1_id, ctx2_id, ctxm_id))
            self.logger.debug('which converts to context: %s, %s' % (ctx1, ctx2))
            
            #
            # now find pairs
            for molid_fragid_uid_L in query_dict[ctxm_id]:
                molid_L, frag_id_L = inv_cantor(molid_fragid_uid_L)
                frag_L = self.refsmi_dict[frag_id_L]

                # check it exists in double_pairs_dict, because it might not if
                # we are comparing data from double_pairs_comparison_dict
                if ctxm_id in self.double_pairs_dict:
                    for molid_fragid_uid_R in self.double_pairs_dict[ctxm_id]:
                        molid_R, frag_id_R = inv_cantor(molid_fragid_uid_R)
                        # print "Working with molid_l=%s, molid_r=%s, ctx=%s, frag_L=%s, frag_r=%s" %
                        #     (molid_L, molid_R, ctx, frag_L, self.refsmi_dict[frag_id_R] )
                        if molid_L != molid_R:
                            frag_R = self.refsmi_dict[frag_id_R]
                            # need to remove pairs where the original smiles was identical for both molid
                            # which results in a pair with frag_l == frag_r and is not of interest
                            # this mostly occurs because we do not handle chirality
                            # this simple if string comparison statement is expensive and slows code down!
                            if frag_L != frag_R:

                                # At this point we have a pair!
                                # Some cases exist where multiple fragmentations for the same input smiles give the
                                # same context but different frag. This is due to isomeric substitution e.g.: two
                                # different Me groups off a core. These are still valid matches but could be removed
                                # by ensuring that the original smiles is also different

                                # finally get the attachment point info back from the numeric id's
                                fattach_str_R = self.refattach_dict[
                                    self.double_pairs_dict[ctxm_id][molid_fragid_uid_R][0]]
                                cattach_str_R = self.refattach_dict[
                                    self.double_pairs_dict[ctxm_id][molid_fragid_uid_R][1]]
                                fattach_str_L = self.refattach_dict[query_dict[ctxm_id][molid_fragid_uid_L][0]]
                                cattach_str_L = self.refattach_dict[query_dict[ctxm_id][molid_fragid_uid_L][1]]

                                yield molid_L, molid_R, ctx, frag_L, frag_R, fattach_str_L, cattach_str_L, \
                                      fattach_str_R, cattach_str_R

    def iterator_double_pairs_dict(self, use_comparison_dict=False):

        """Method to iterate over Double Cut Dictionary structure and yield pairs"""

        for molid_L, molid_R, ctx, frag_L, frag_R, fattach_str_L, cattach_str_L, fattach_str_R, cattach_str_R \
                in self.__subiterator_double_pairs_dict(use_comparison_dict):

            for count_ in range(2):
               
                # yield the pair twice, first raw data, second with flipped numbering
                if count_ == 0:

                    # print molid_L, molid_R, ctx, frag_L, frag_R, fattach_str_L, cattach_str_L, fattach_str_R,
                    #     cattach_str_R
                    yield molid_L, molid_R, ctx, frag_L, frag_R, fattach_str_L, cattach_str_L, fattach_str_R, \
                          cattach_str_R
                
                else:

                    ctx = ctx.replace("[1", "[9")
                    ctx = ctx.replace("[2", "[1")
                    ctx = ctx.replace("[9", "[2")
                    
                    if '[12' not in frag_L:
                        frag_L = frag_L.replace("[1", "[9")
                        frag_L = frag_L.replace("[2", "[1")
                        frag_L = frag_L.replace("[9", "[2")

                    if '[12' not in frag_R:
                        frag_R = frag_R.replace("[1", "[9")
                        frag_R = frag_R.replace("[2", "[1")
                        frag_R = frag_R.replace("[9", "[2")
                    
                    # regex to flip the numbers in the attachment points
                    fattach_str_L = re.sub("\[(\d)(.*)\|(\d)(.*)", r"[\3\2|\1\4", fattach_str_L)
                    cattach_str_L = re.sub("\[(\d)(.*)\|(\d)(.*)", r"[\3\2|\1\4", cattach_str_L)
                    fattach_str_R = re.sub("\[(\d)(.*)\|(\d)(.*)", r"[\3\2|\1\4", fattach_str_R)
                    cattach_str_R = re.sub("\[(\d)(.*)\|(\d)(.*)", r"[\3\2|\1\4", cattach_str_R)

                    # print "-F-> ", molid_L, molid_R, ctx, frag_L, frag_R, fattach_str_L, cattach_str_L,
                    #     fattach_str_R, cattach_str_R

                    yield molid_L, molid_R, ctx, frag_L, frag_R, fattach_str_L, cattach_str_L, fattach_str_R, \
                        cattach_str_R

    def _inspector_double_pairs_dict(self):
        """Method is simply used in validation work, it's not algorithmically useful.  The code will confirm that
        dicer is canonicalising the double cut context fragments correctly.  Incorrect canonicalisation will result
        in a double cut being represented in two different ways and stored independently, with different fragments
        against each case.  Pairs will be missed as you only find mmp's for each of the different representations and
        not between the two representations.  Correct canonicalisation will ensure this does not happen.  The code
        below is searching for cases where two different canonicalised forms are stored with different fragments.  The
        code should not return any results, thus proving that canonicalisation is done correctly.  Example validation
        test code would be:

            def test_inspector_double_cut_pairs(self):
                self.test_mmp_object.build_from_dicer("twomillionsmi.smi", 'DOUBLE', 'NONE')
                self.test_mmp_object.inspector_double_pairs_dict()

        Ran on with 2.1M smi and no results were returned (no print to cmd line)
        unit test switched back to smiple input file
        """

        # regex to find contexts that have a fragmentation point label of '1'
        regex_context1 = re.compile(r'\[1\w{1,3}\]')

        counter = 0

        for ctxm_id in self.double_pairs_dict:

            counter += 1
            # if (counter % 1000) == 0:
            #    print "Iteration: ", counter

            # first deconvolute the context ids so we can get back the smiles
            ctx1_id, ctx2_id = inv_cantor(ctxm_id)

            ctx1_smi = self.refsmi_dict[ctx1_id]
            ctx2_smi = self.refsmi_dict[ctx2_id]

            if regex_context1.search(ctx1_smi) is not None:
                # got [1 so flip
                ctx1_smi_flipped = ctx1_smi.replace("[1", "[2")
                ctx2_smi_flipped = ctx2_smi.replace("[2", "[1")

            else:
                ctx1_smi_flipped = ctx1_smi.replace("[2", "[1")
                ctx2_smi_flipped = ctx2_smi.replace("[1", "[2")

            if ctx1_smi_flipped in self.refsmi_dict:
                ctx1_id_flipped = self.refsmi_dict[ctx1_smi_flipped]
            else:
                ctx1_id_flipped = None

            if ctx2_smi_flipped in self.refsmi_dict:
                ctx2_id_flipped = self.refsmi_dict[ctx2_smi_flipped]
            else:
                ctx2_id_flipped = None

            if ctx1_id_flipped is not None and ctx2_id_flipped is not None:

                ctxm_id_flipped = cantor(ctx1_id_flipped, ctx2_id_flipped)

                if ctxm_id_flipped in self.double_pairs_dict:

                    # print "Iteration: ", counter, " had a duplicate reversed entry ctx smi"
                    if self.double_pairs_dict[ctxm_id] != self.double_pairs_dict[ctxm_id_flipped]:
                        # # OK, this is bad, it should not happen:
                        print("Original:")
                        print(("{} {}".format(ctxm_id, self.double_pairs_dict[ctxm_id])))
                        print("Double")
                        print(("{} {}".format(ctxm_id_flipped, self.double_pairs_dict[ctxm_id_flipped])))

    def print_to_file(self, out_fi, cut_type, inc_types_header=False):
        """Method to get pairs from the base data object of the class

        out_fi:
          The user specified output file
        
        cut_type:
          Specifies the type of fragmentation required.  Allowed values are SINGLE,
          DOUBLE or BOTH.  Currently this class does not support anything greater than
          double cut fragmentation
        
        Example usage:

            # give me a CSV named my_output.pairs of all the pairs:
            my_mmp_object.print_to_file('my_output.pairs', 'CSV', 'BOTH')

            # give me a CSV of only the DOUBLE cut pairs:
            my_mmp_object.print_to_file('my_output.pairs', 'CSV', 'DOUBLE')
        """

        # check file write possible before start
        self.logger.info('Opening output file for write: %s' % out_fi)

        # check cut_type, convert to int
        if cut_type.upper() == 'DOUBLE':
            # confusing but faster later
            cut_type_id = 3
        elif cut_type.upper() == 'BOTH':
            # confusing but faster later
            cut_type_id = 2
        elif cut_type.upper() == 'SINGLE':
            cut_type_id = 1
        else:
            self.logger.warn('cut_type specification is incorrect, using single cut: %s' % cut_type.upper())
            cut_type_id = 1

        # Now start processing the data structures to write the pairs
        with open(out_fi, "w") as f:

            #
            # write single header line
            #

            f.write("CUT,MOLID_L,MOLID_R,CONTEXT,FRAG_L,FRAG_R,ATTCHPT_FRAG_L,"
                    "ATTCHPT_CTX_L,ATTCHPT_FRAG_R,ATTCHPT_CTX_R\n")
            if inc_types_header:
                f.write("STRING,STRING,STRING,SMILES,SMILES,SMILES,STRING,STRING,STRING,STRING\n")
            
            #
            # print pairs for single
            if cut_type_id <= 2:
                # for molid_L, molid_R, ctx, frag_L, frag_R in self.iterator_single_pairs_dict():
                for molid_L, molid_R, ctx, frag_L, frag_R, fa_L, ca_L, fa_R, ca_R \
                        in self.iterator_single_pairs_dict():
                    f.write('single,%d,%d,%s,%s,%s,%s,%s,%s,%s\n' % (molid_L, molid_R, ctx, frag_L, frag_R, fa_L, ca_L,
                                                                     fa_R, ca_R))

            #
            # print pairs for double
            if cut_type_id >= 2:
                # for molid_L, molid_R, ctx, frag_L, frag_R in self.iterator_double_pairs_dict():
                for molid_L, molid_R, ctx, frag_L, frag_R, fa_L, ca_L, fa_R, ca_R \
                        in self.iterator_double_pairs_dict():
                    f.write('double,%d,%d,%s,%s,%s,%s,%s,%s,%s\n' % (molid_L, molid_R, ctx, frag_L, frag_R, fa_L, ca_L,
                                                                     fa_R, ca_R))

        # close the file handle
        f.close()

        self.logger.info('All done!')


class _TestMMPObjectClass(unittest.TestCase):

    """Test class for MMPObjectClass(object) written to use pythons unittest

    Example usage:
     
     python mmp_objects.py
     
     coverage run mmp_objects.py
     coverage report mmp_objects.py

    """

    def setUp(self):

        """Instantiate temp file names, test data objects that get written to temp files
        a silent logger object (needed to instantiate class) and the mmp object we'll test"""

        self.maxDiff = None

        self.temp_file_input_smi = tempfile.NamedTemporaryFile(delete=False, encoding='utf-8', mode='wt')
        self.temp_file_input_smi_1b = tempfile.NamedTemporaryFile(delete=False, encoding='utf-8', mode='wt')
        self.temp_file_input_smi_2 = tempfile.NamedTemporaryFile(delete=False, encoding='utf-8', mode='wt')
        self.temp_file_output_pairs = tempfile.NamedTemporaryFile(delete=False, encoding='utf-8', mode='wt')

        self.mmplogger = logging.getLogger('mmpobjectclass_testlogger')
        logging.disable(logging.CRITICAL)

        self.test_mmp_object = MMPObjectClass(self.mmplogger)

        # input is a set of smiles to generate pairs from
        # golden output data sets are the expected output from the code we'll run during the test
        self.test_dataset_input_smi_01 = {

            # basic test set
            # CHEMBL3105327 https://www.ebi.ac.uk/chembl/compound_report_card/CHEMBL3105327/
            '3105327': 'Cc1ccc2c(ccn2c3nc(cs3)c4cc(ccc4F)C(F)(F)F)c1',
            # CHEMBL1526778 https://www.ebi.ac.uk/chembl/compound_report_card/CHEMBL1526778/
            '1526778': 'CC(=O)c1c(C)n(c(C)c1C(=O)C)c2nc(c(C)s2)c3ccc(C)c(C)c3',
            # CHEMBL1494678 https://www.ebi.ac.uk/chembl/compound_report_card/CHEMBL1494678/
            '1494678': 'CC(=O)c1c(C)n(c(C)c1C(=O)C)c2nc(c(C)s2)c3ccccc3',

            # test a bug converting double cut label [12 to [21
            # CHEMBL472166
            '472166': 'OC(CCn1ccnc1)(c2ccccc2)c3ccccc3',
            # CHEMBL69798
            '69798': 'Cc1nccn1CCC(O)(c2ccccc2)c3ccccc3',

            }

        self.test_dataset_input_smi_01b = {
            # no pairs from these extras
            # CHEMBL367346 https://www.ebi.ac.uk/chembl/compound_report_card/CHEMBL367346/
            '367346': 'Cc1sc(N)nc1c2cccc(Cl)c2',
            # https://www.ebi.ac.uk/chembl/compound_report_card/CHEMBL366881/
            '366881': 'Cc1sc(N)nc1c2ccc(Cl)c(Cl)c2'
                }

        self.test_dataset_input_smi_02 = {
            # CHEMBL1477460 https://www.ebi.ac.uk/chembl/compound_report_card/CHEMBL1477460/
            '1477460': 'COc1ccc(cc1)c2nc(sc2C)n3c(C)c(C(=O)C)c(C(=O)C)c3C',
            # CHEMBL1441050 https://www.ebi.ac.uk/chembl/compound_report_card/CHEMBL1441050/
            '1441050': 'COc1ccc(cc1OC)c2nc(sc2C)n3c(C)c(C(=O)C)c(C(=O)C)c3C'
                }

        self.test_dataset_goldenoutput_pairs_01 = {
            'CUT,MOLID_L,MOLID_R,CONTEXT,FRAG_L,FRAG_R,ATTCHPT_FRAG_L,ATTCHPT_CTX_L,ATTCHPT_FRAG_R,ATTCHPT_CTX_R': None,
            'double,1526778,1494678,[1CH4].Cc1[2nH]c(c(c1C(=O)C)C(=O)C)C,Cc1ccc(c2[n][2cH]s[1cH]2)cc1C,s1[2cH][n]c(c2ccccc2)[1cH]1,[2:NPL3|1:C3],[1:C2|2:C2],[2:NPL3|1:C3],[1:C2|2:C2]': None,
            'double,1526778,1494678,[2CH4].Cc1[1nH]c(c(c1C(=O)C)C(=O)C)C,Cc1ccc(c2[n][1cH]s[2cH]2)cc1C,s1[1cH][n]c(c2ccccc2)[2cH]1,[1:NPL3|2:C3],[2:C2|1:C2],[1:NPL3|2:C3],[2:C2|1:C2]': None,
            'double,1526778,1494678,[1CH4].Cc1[2nH]c(c(c1C(=O)C)C(=O)C)C,Cc1s[2cH][n]c1c1cc([1cH]cc1)C,s1[2cH][n]c(c2ccccc2)[1cH]1,[2:NPL3|1:C3],[1:CAR|2:C2],[2:NPL3|1:C3],[1:C2|2:C2]': None,
            'double,1526778,1494678,[2CH4].Cc1[1nH]c(c(c1C(=O)C)C(=O)C)C,Cc1s[1cH][n]c1c1cc([2cH]cc1)C,s1[1cH][n]c(c2ccccc2)[2cH]1,[1:NPL3|2:C3],[2:CAR|1:C2],[1:NPL3|2:C3],[2:C2|1:C2]': None,
            'double,1526778,1494678,[1CH4].Cc1[2nH]c(c(c1C(=O)C)C(=O)C)C,Cc1s[2cH][n]c1c1c[1cH]c(cc1)C,s1[2cH][n]c(c2ccccc2)[1cH]1,[2:NPL3|1:C3],[1:CAR|2:C2],[2:NPL3|1:C3],[1:C2|2:C2]': None,
            'double,1526778,1494678,[2CH4].Cc1[1nH]c(c(c1C(=O)C)C(=O)C)C,Cc1s[1cH][n]c1c1c[2cH]c(cc1)C,s1[1cH][n]c(c2ccccc2)[2cH]1,[1:NPL3|2:C3],[2:CAR|1:C2],[1:NPL3|2:C3],[2:C2|1:C2]': None,
            'double,1494678,1526778,[1CH4].Cc1[2nH]c(c(c1C(=O)C)C(=O)C)C,s1[2cH][n]c(c2ccccc2)[1cH]1,Cc1ccc(c2[n][2cH]s[1cH]2)cc1C,[2:NPL3|1:C3],[1:C2|2:C2],[2:NPL3|1:C3],[1:C2|2:C2]': None,
            'double,1494678,1526778,[2CH4].Cc1[1nH]c(c(c1C(=O)C)C(=O)C)C,s1[1cH][n]c(c2ccccc2)[2cH]1,Cc1ccc(c2[n][1cH]s[2cH]2)cc1C,[1:NPL3|2:C3],[2:C2|1:C2],[1:NPL3|2:C3],[2:C2|1:C2]': None,
            'double,1494678,1526778,[1CH4].Cc1[2nH]c(c(c1C(=O)C)C(=O)C)C,s1[2cH][n]c(c2ccccc2)[1cH]1,Cc1s[2cH][n]c1c1cc([1cH]cc1)C,[2:NPL3|1:C3],[1:C2|2:C2],[2:NPL3|1:C3],[1:CAR|2:C2]': None,
            'double,1494678,1526778,[2CH4].Cc1[1nH]c(c(c1C(=O)C)C(=O)C)C,s1[1cH][n]c(c2ccccc2)[2cH]1,Cc1s[1cH][n]c1c1cc([2cH]cc1)C,[1:NPL3|2:C3],[2:C2|1:C2],[1:NPL3|2:C3],[2:CAR|1:C2]': None,
            'double,1494678,1526778,[1CH4].Cc1[2nH]c(c(c1C(=O)C)C(=O)C)C,s1[2cH][n]c(c2ccccc2)[1cH]1,Cc1s[2cH][n]c1c1c[1cH]c(cc1)C,[2:NPL3|1:C3],[1:C2|2:C2],[2:NPL3|1:C3],[1:CAR|2:C2]': None,
            'double,1494678,1526778,[2CH4].Cc1[1nH]c(c(c1C(=O)C)C(=O)C)C,s1[1cH][n]c(c2ccccc2)[2cH]1,Cc1s[1cH][n]c1c1c[2cH]c(cc1)C,[1:NPL3|2:C3],[2:C2|1:C2],[1:NPL3|2:C3],[2:CAR|1:C2]': None,
            'double,472166,69798,[1cH]1ccccc1.[2cH]1ccccc1,O[12CH2]CC[n]1c[n]cc1,O[12CH2]CC[n]1c([n]cc1)C,[2:CAR|1:CAR],[1:C3|2:C3],[2:CAR|1:CAR],[1:C3|2:C3]': None,
            'double,472166,69798,[2cH]1ccccc1.[1cH]1ccccc1,O[12CH2]CC[n]1c[n]cc1,O[12CH2]CC[n]1c([n]cc1)C,[1:CAR|2:CAR],[2:C3|1:C3],[1:CAR|2:CAR],[2:C3|1:C3]': None,
            'double,69798,472166,[1cH]1ccccc1.[2cH]1ccccc1,O[12CH2]CC[n]1c([n]cc1)C,O[12CH2]CC[n]1c[n]cc1,[2:CAR|1:CAR],[1:C3|2:C3],[2:CAR|1:CAR],[1:C3|2:C3]': None,
            'double,69798,472166,[2cH]1ccccc1.[1cH]1ccccc1,O[12CH2]CC[n]1c([n]cc1)C,O[12CH2]CC[n]1c[n]cc1,[1:CAR|2:CAR],[2:C3|1:C3],[1:CAR|2:CAR],[2:C3|1:C3]': None}

        self.test_dataset_goldenoutput_pairs_02 = {
            'CUT,MOLID_L,MOLID_R,CONTEXT,FRAG_L,FRAG_R,ATTCHPT_FRAG_L,ATTCHPT_CTX_L,ATTCHPT_FRAG_R,ATTCHPT_CTX_R': None,
            'STRING,STRING,STRING,SMILES,SMILES,SMILES,STRING,STRING,STRING,STRING': None,
            'single,1526778,1494678,Cc1sc([n]2c(c(c(c2C)C(=O)C)C(=O)C)C)[n][1cH]1,Cc1cc[1cH]cc1C,[1cH]1ccccc1,[1:C2],[1:CAR],[1:C2],[1:CAR]': None,
            'single,1494678,1526778,Cc1sc([n]2c(c(c(c2C)C(=O)C)C(=O)C)C)[n][1cH]1,[1cH]1ccccc1,Cc1cc[1cH]cc1C,[1:C2],[1:CAR],[1:C2],[1:CAR]': None,
            'single,472166,69798,O[1CH](c1ccccc1)c1ccccc1,[1CH3]C[n]1c[n]cc1,[1CH3]C[n]1c([n]cc1)C,[1:C3],[1:C3],[1:C3],[1:C3]': None,
            'single,69798,472166,O[1CH](c1ccccc1)c1ccccc1,[1CH3]C[n]1c([n]cc1)C,[1CH3]C[n]1c[n]cc1,[1:C3],[1:C3],[1:C3],[1:C3]': None,
            'single,472166,69798,OC([1CH3])(c1ccccc1)c1ccccc1,[1CH3][n]1c[n]cc1,[1CH3][n]1c([n]cc1)C,[1:C3],[1:C3],[1:C3],[1:C3]': None,
            'single,69798,472166,OC([1CH3])(c1ccccc1)c1ccccc1,[1CH3][n]1c([n]cc1)C,[1CH3][n]1c[n]cc1,[1:C3],[1:C3],[1:C3],[1:C3]': None,
            'single,472166,69798,OC(C[1CH3])(c1ccccc1)c1ccccc1,[1nH]1c[n]cc1,Cc1[1nH]cc[n]1,[1:C3],[1:NPL3],[1:C3],[1:NPL3]': None,
            'single,69798,472166,OC(C[1CH3])(c1ccccc1)c1ccccc1,Cc1[1nH]cc[n]1,[1nH]1c[n]cc1,[1:C3],[1:NPL3],[1:C3],[1:NPL3]': None,
            'single,472166,69798,OC(CC[n]1[1cH][n]cc1)(c1ccccc1)c1ccccc1,[1H],[1CH4],[1:C2],[1:H],[1:C2],[1:C3]': None,
            'single,69798,472166,OC(CC[n]1[1cH][n]cc1)(c1ccccc1)c1ccccc1,[1CH4],[1H],[1:C2],[1:C3],[1:C2],[1:H]': None}

        self.test_dataset_goldenoutput_pairs_03 = {
            'CUT,MOLID_L,MOLID_R,CONTEXT,FRAG_L,FRAG_R,ATTCHPT_FRAG_L,ATTCHPT_CTX_L,ATTCHPT_FRAG_R,ATTCHPT_CTX_R': None,
            'STRING,STRING,STRING,SMILES,SMILES,SMILES,STRING,STRING,STRING,STRING': None,
            'single,1526778,1494678,Cc1sc([n]2c(c(c(c2C)C(=O)C)C(=O)C)C)[n][1cH]1,Cc1cc[1cH]cc1C,[1cH]1ccccc1,[1:C2],[1:CAR],[1:C2],[1:CAR]': None,
            'single,1494678,1526778,Cc1sc([n]2c(c(c(c2C)C(=O)C)C(=O)C)C)[n][1cH]1,[1cH]1ccccc1,Cc1cc[1cH]cc1C,[1:C2],[1:CAR],[1:C2],[1:CAR]': None,
            'single,472166,69798,O[1CH](c1ccccc1)c1ccccc1,[1CH3]C[n]1c[n]cc1,[1CH3]C[n]1c([n]cc1)C,[1:C3],[1:C3],[1:C3],[1:C3]': None,
            'single,69798,472166,O[1CH](c1ccccc1)c1ccccc1,[1CH3]C[n]1c([n]cc1)C,[1CH3]C[n]1c[n]cc1,[1:C3],[1:C3],[1:C3],[1:C3]': None,
            'single,472166,69798,OC([1CH3])(c1ccccc1)c1ccccc1,[1CH3][n]1c[n]cc1,[1CH3][n]1c([n]cc1)C,[1:C3],[1:C3],[1:C3],[1:C3]': None,
            'single,69798,472166,OC([1CH3])(c1ccccc1)c1ccccc1,[1CH3][n]1c([n]cc1)C,[1CH3][n]1c[n]cc1,[1:C3],[1:C3],[1:C3],[1:C3]': None,
            'single,472166,69798,OC(C[1CH3])(c1ccccc1)c1ccccc1,[1nH]1c[n]cc1,Cc1[1nH]cc[n]1,[1:C3],[1:NPL3],[1:C3],[1:NPL3]': None,
            'single,69798,472166,OC(C[1CH3])(c1ccccc1)c1ccccc1,Cc1[1nH]cc[n]1,[1nH]1c[n]cc1,[1:C3],[1:NPL3],[1:C3],[1:NPL3]': None}

        self.test_dataset_goldenoutput_pairs_04 = copy.deepcopy(self.test_dataset_goldenoutput_pairs_03)
        self.test_dataset_goldenoutput_pairs_04['STRING,STRING,STRING,SMILES,SMILES,SMILES,STRING,STRING,STRING,STRING'] = None

        self.test_dataset_goldenoutput_pairs_05 = {
            (1477460, 1494678, 'Cc1sc([n]2c(c(c(c2C)C(=O)C)C(=O)C)C)[n]c1c1cc[1cH]cc1'): ('[1OH]C', '[1H]'),
            (1477460, 1526778, 'Cc1sc([n]2c(c(c(c2C)C(=O)C)C(=O)C)C)[n][1cH]1'): ('COc1cc[1cH]cc1', 'Cc1cc[1cH]cc1C'),
            (1477460, 1494678, 'Cc1sc([n]2c(c(c(c2C)C(=O)C)C(=O)C)C)[n][1cH]1'): ('COc1cc[1cH]cc1', '[1cH]1ccccc1'),
            (1441050, 1526778, 'Cc1sc([n]2c(c(c(c2C)C(=O)C)C(=O)C)C)[n][1cH]1'): ('COc1cc[1cH]cc1OC', 'Cc1cc[1cH]cc1C'),
            (1441050, 1494678, 'Cc1sc([n]2c(c(c(c2C)C(=O)C)C(=O)C)C)[n][1cH]1'): ('COc1cc[1cH]cc1OC', '[1cH]1ccccc1')}

        self.test_dataset_goldenoutput_pairs_06 = {
            (1477460, 1526778, '[1CH4].Cc1sc([n]2c(c(c(c2C)C(=O)C)C(=O)C)C)[n][2cH]1'): (
            '[1OH]c1cc[2cH]cc1', 'Cc1[1cH]c[2cH]cc1'),
            (1477460, 1526778, '[2CH4].Cc1sc([n]2c(c(c(c2C)C(=O)C)C(=O)C)C)[n][1cH]1'): (
            '[2OH]c1cc[1cH]cc1', 'Cc1[2cH]c[1cH]cc1'),
            (1441050, 1526778, '[1CH4].Cc1sc([n]2c(c(c(c2C)C(=O)C)C(=O)C)C)[n][2cH]1'): (
            '[1OH]c1c(OC)cc[2cH]c1', 'Cc1[1cH]c[2cH]cc1'),
            (1441050, 1526778, '[2CH4].Cc1sc([n]2c(c(c(c2C)C(=O)C)C(=O)C)C)[n][1cH]1'): (
            '[2OH]c1c(OC)cc[1cH]c1', 'Cc1[2cH]c[1cH]cc1'), (1477460, 1526778, '[1CH4].Cc1[2nH]c(c(c1C(=O)C)C(=O)C)C'): (
            'COc1ccc(c2[n][2cH]s[1cH]2)cc1', 'Cc1s[2cH][n]c1c1c[1cH]c(cc1)C'),
            (1477460, 1526778, '[2CH4].Cc1[1nH]c(c(c1C(=O)C)C(=O)C)C'): (
            'COc1ccc(c2[n][1cH]s[2cH]2)cc1', 'Cc1s[1cH][n]c1c1c[2cH]c(cc1)C'),
            (1477460, 1494678, '[1CH4].Cc1[2nH]c(c(c1C(=O)C)C(=O)C)C'): (
            'COc1ccc(c2[n][2cH]s[1cH]2)cc1', 's1[2cH][n]c(c2ccccc2)[1cH]1'),
            (1477460, 1494678, '[2CH4].Cc1[1nH]c(c(c1C(=O)C)C(=O)C)C'): (
            'COc1ccc(c2[n][1cH]s[2cH]2)cc1', 's1[1cH][n]c(c2ccccc2)[2cH]1')}

        self.test_dataset_goldenoutput_pairs_numeric = {(1526778, 1494678, 31, 30, 47): 1,
                                                        (1494678, 1526778, 31, 47, 30): 1,
                                                        (472166, 69798, 57, 56, 74): 1, (69798, 472166, 57, 74, 56): 1,
                                                        (472166, 69798, 59, 58, 73): 1, (69798, 472166, 59, 73, 58): 1,
                                                        (472166, 69798, 61, 60, 72): 1, (69798, 472166, 61, 72, 60): 1,
                                                        (472166, 69798, 68, 12, 1): 1, (69798, 472166, 68, 1, 12): 1}

        self.test_dataset_goldenoutput_pairs_numeric_threshold03 = {(1526778, 1494678, 25, 24, 40): 1,
                                                                    (1494678, 1526778, 25, 40, 24): 1,
                                                                    (472166, 69798, 52, 51, 63): 1,
                                                                    (69798, 472166, 52, 63, 51): 1,
                                                                    (472166, 69798, 59, 8, 1): 1,
                                                                    (69798, 472166, 59, 1, 8): 1}

        self.test_dataset_goldenoutput_pairs_numeric_ctx = {(1526778, 1494678, 31, 30, 47, 3, 1, 3, 1): 1,
                                                            (1494678, 1526778, 31, 47, 30, 3, 1, 3, 1): 1,
                                                            (472166, 69798, 57, 56, 74, 2, 2, 2, 2): 1,
                                                            (69798, 472166, 57, 74, 56, 2, 2, 2, 2): 1,
                                                            (472166, 69798, 59, 58, 73, 2, 2, 2, 2): 1,
                                                            (69798, 472166, 59, 73, 58, 2, 2, 2, 2): 1,
                                                            (472166, 69798, 61, 60, 72, 2, 4, 2, 4): 1,
                                                            (69798, 472166, 61, 72, 60, 2, 4, 2, 4): 1,
                                                            (472166, 69798, 68, 12, 1, 3, 6, 3, 2): 1,
                                                            (69798, 472166, 68, 1, 12, 3, 2, 3, 6): 1}

        # write test data to temp file 01
        for smi_id, smi in list(self.test_dataset_input_smi_01.items()):
            self.temp_file_input_smi.write(smi+" "+smi_id+"\n")
        self.temp_file_input_smi.close()

        # write test data to temp file 01b
        for smi_id, smi in list(self.test_dataset_input_smi_01.items()):
            self.temp_file_input_smi_1b.write(smi+" "+smi_id+"\n")
        for smi_id, smi in list(self.test_dataset_input_smi_01b.items()):
            self.temp_file_input_smi_1b.write(smi+" "+smi_id+"\n")
        self.temp_file_input_smi_1b.close()

        # write test data to temp file 02
        for smi_id, smi in list(self.test_dataset_input_smi_02.items()):
            self.temp_file_input_smi_2.write(smi+" "+smi_id+"\n")
        self.temp_file_input_smi_2.close()

        # container for results data
        self.test_dataset_testresults = {}

    def tearDown(self):
        
        """Tear down object for clean reuse in further tests"""
        self.test_mmp_object.clean_out_data()
        self.test_dataset_testresults.clear()

    def test_singlecutpairs_yieldnumeric(self):

        """Test the generation of single cut pairs with output"""

        # test the MMPObjectClass using above temp file, then write to new output
        self.test_mmp_object.build_from_dicer(self.temp_file_input_smi.name, 'SINGLE', 'NONE')
       
        for molid_L, molid_R, ctx_id, frag_id_L, frag_id_R in self.test_mmp_object.iterator_single_pairs_dict_numeric():
            self.test_dataset_testresults[molid_L, molid_R, ctx_id, frag_id_L, frag_id_R] = 1

        #print(self.test_dataset_testresults)
        self.assertEqual(self.test_dataset_testresults, self.test_dataset_goldenoutput_pairs_numeric)

    def test_singlecutpairs_yieldnumeric_ctx(self):
        """Test the generation of single cut pairs with output"""

        self.test_mmp_object.build_from_dicer(self.temp_file_input_smi.name, 'SINGLE', 'NONE')
       
        for molid_L, molid_R, ctx_id, frag_id_L, frag_id_R, fattach_L, cattach_L, fattach_R, cattach_R in \
                self.test_mmp_object.iterator_single_pairs_dict_numeric(inc_attachpt = True):
            self.test_dataset_testresults[molid_L, molid_R, ctx_id, frag_id_L, frag_id_R, fattach_L, cattach_L,
                                          fattach_R, cattach_R] = 1

        #print(self.test_dataset_testresults)
        self.assertEqual(self.test_dataset_testresults, self.test_dataset_goldenoutput_pairs_numeric_ctx)

    def test_doublecutpairs_yieldnumeric(self):
        """Test as per test_singlecutpairs_numeric but utilises double cut methods"""

        # generate base objects as in test_build_from_dicer_comparison_dict_true
        self.test_mmp_object.build_from_dicer(self.temp_file_input_smi.name, 'DOUBLE', 'NONE')

        # test_results_filehandle = open(self.temp_file_output_pairs.name, 'r')
        for molid_L, molid_R, ctx1_id, ctx2_id, frag_L_id, frag_R_id, fa_L_id, ca_L_id, fa_R_id, ca_R_id \
                in self.test_mmp_object.iterator_double_pairs_dict_numeric(inc_attachpt=True):

            ctx_str = self.test_mmp_object.refsmi_dict[ctx1_id] + "." + self.test_mmp_object.refsmi_dict[ctx2_id]

            # print molid_L, molid_R, ctx_str
            # print self.test_mmp_object.refsmi_dict[frag_L_id], self.test_mmp_object.refsmi_dict[frag_R_id],
            # print self.test_mmp_object.refattach_dict[fa_L_id], self.test_mmp_object.refattach_dict[ca_L_id],
            # print self.test_mmp_object.refattach_dict[fa_R_id], self.test_mmp_object.refattach_dict[ca_R_id]

            key = (molid_L, molid_R, ctx_str, self.test_mmp_object.refsmi_dict[frag_L_id],
                   self.test_mmp_object.refsmi_dict[frag_R_id])
            val = (self.test_mmp_object.refattach_dict[fa_L_id], self.test_mmp_object.refattach_dict[ca_L_id],
                   self.test_mmp_object.refattach_dict[fa_R_id], self.test_mmp_object.refattach_dict[ca_R_id])
            self.test_dataset_testresults[key] = val

        # repeat non numeric
        comparison_test_dataset_testresults = {}
        for molid_L, molid_R, ctx, frag_L, frag_R, fa_L, ca_L, fa_R, ca_R \
                in self.test_mmp_object.iterator_double_pairs_dict():

            # print molid_L, molid_R, ctx, frag_L, frag_R, fa_L, ca_L, fa_R, ca_R
            comparison_test_dataset_testresults[(molid_L, molid_R, ctx, frag_L, frag_R)] = (fa_L, ca_L, fa_R, ca_R)

        #print(self.test_dataset_testresults) # use this pprint statement to regenerate the golden data
        self.assertEqual(comparison_test_dataset_testresults, self.test_dataset_testresults)

    def test_build_from_dicer_comparison_dict_true(self):
    
        """Test the generation of single cut pairs but also create comparison dict without altering pairs in
        original object.  All this test does is ensure we don't cross contaminate the dicts"""
        
        # This test ensures that the flag "use_comparison_dict = True" will work correctly by populating
        # a second independent comparison pairs dict object without altering the base pairs dict
        self.test_mmp_object.build_from_dicer(self.temp_file_input_smi.name, 'SINGLE', 'NONE')
        self.test_mmp_object.build_from_dicer(self.temp_file_input_smi_2.name, 'SINGLE', 'NONE',
                                              use_comparison_dict=True)

        for molid_L, molid_R, ctx_id, frag_id_L, frag_id_R in self.test_mmp_object.iterator_single_pairs_dict_numeric():
            self.test_dataset_testresults[molid_L, molid_R, ctx_id, frag_id_L, frag_id_R] = 1

        #print(self.test_dataset_testresults)
        self.assertEqual(self.test_dataset_testresults, self.test_dataset_goldenoutput_pairs_numeric)

    def test_build_from_dicer_threshold(self):

        """Test the generation of single cut pairs but also create comparison dict without altering pairs in
        original object.  All this test does is ensure we don't cross contaminate the dicts"""

        # This test ensures that the flag "use_comparison_dict = True" will work correctly by populating
        # a second independant comparison pairs dict object without altering the base pairs dict
        self.test_mmp_object.build_from_dicer(self.temp_file_input_smi.name, 'SINGLE', 'NONE', threshold=0.30001)

        for molid_L, molid_R, ctx_id, frag_id_L, frag_id_R in self.test_mmp_object.iterator_single_pairs_dict_numeric():
            self.test_dataset_testresults[molid_L, molid_R, ctx_id, frag_id_L, frag_id_R] = 1

        #print(self.test_dataset_testresults)
        self.assertEqual(self.test_dataset_testresults, self.test_dataset_goldenoutput_pairs_numeric_threshold03)

    def test_singlecutpairs(self):
        """Test the generation of single cut pairs with output"""

        self.test_mmp_object.build_from_dicer(self.temp_file_input_smi.name, 'SINGLE', 'NONE')
        self.test_mmp_object.print_to_file(self.temp_file_output_pairs.name, 'SINGLE', 'DICER')

        test_results_filehandle = open(self.temp_file_output_pairs.name, 'r')
        for line in test_results_filehandle:
            line = line.rstrip('\r')
            line = line.rstrip('\n')
            self.test_dataset_testresults[line] = None
        
        #print(self.test_dataset_testresults) # use this pprint statement to regenerate the golden data
        self.assertEqual(self.test_dataset_testresults, self.test_dataset_goldenoutput_pairs_02)

    def test_doublecutpairs(self):

        """Test the generation of double cut pairs with CSV output"""

        self.test_mmp_object.build_from_dicer(self.temp_file_input_smi.name, 'DOUBLE', 'NONE')
        self.test_mmp_object.print_to_file(self.temp_file_output_pairs.name, 'DOUBLE')

        test_results_filehandle = open(self.temp_file_output_pairs.name, 'r')
        for line in test_results_filehandle:
            line = line.rstrip('\r')
            line = line.rstrip('\n')
            self.test_dataset_testresults[line] = None

        #print(">>> ", self.test_dataset_testresults)
        self.assertEqual(self.test_dataset_testresults, self.test_dataset_goldenoutput_pairs_01)

    def test_singlecutpairs_comparison_dict_true(self):
        
        """This test compares the different contexts found in single_pairs_comparison_dict to those in
        single_pairs_dict.  When we find a match then we have found a pair between the two different 
        sets of smiles.  This method is used in approaches like mmp_prediction when we need a delta value
        from an existing pair to predict data for a new smiles"""

        # generate base objects as in test_build_from_dicer_comparison_dict_true
        self.test_mmp_object.build_from_dicer(self.temp_file_input_smi.name, 'SINGLE', 'NONE')
        self.test_mmp_object.build_from_dicer(self.temp_file_input_smi_2.name, 'SINGLE', 'NONE',
                                              use_comparison_dict=True)

        # test_results_filehandle = open(self.temp_file_output_pairs.name, 'r')
        for molid_L, molid_R, ctx, frag_L, frag_R, fa_L, ca_L, fa_R, ca_R \
                in self.test_mmp_object.iterator_single_pairs_dict(use_comparison_dict=True):
            self.test_dataset_testresults[(molid_L, molid_R, ctx)] = (frag_L, frag_R)
                
        #print(self.test_dataset_testresults) # use this pprint statement to regenerate the golden data
        self.assertEqual(self.test_dataset_testresults, self.test_dataset_goldenoutput_pairs_05)

    def test_doublecutpairs_comparison_dict_true(self):

        """Test as per test_singlecutpairs_comparison_dict_true but utilises double cut methods"""
        
        # generate base objects as in test_build_from_dicer_comparison_dict_true
        self.test_mmp_object.build_from_dicer(self.temp_file_input_smi.name, 'DOUBLE', 'NONE')
        self.test_mmp_object.build_from_dicer(self.temp_file_input_smi_2.name, 'DOUBLE', 'NONE',
                                              use_comparison_dict=True)

        # test_results_filehandle = open(self.temp_file_output_pairs.name, 'r')
        for molid_L, molid_R, ctx, frag_L, frag_R, fa_L, ca_L, fa_R, ca_R \
                in self.test_mmp_object.iterator_double_pairs_dict(use_comparison_dict=True):
                self.test_dataset_testresults[(molid_L, molid_R, ctx)] = (frag_L, frag_R)

        #print(self.test_dataset_testresults) # use this pprint statement to regenerate the golden data
        self.assertEqual(self.test_dataset_testresults, self.test_dataset_goldenoutput_pairs_06)

    def test_singlecutpairs_typesheaders(self):

        """Test the generation of single cut pairs with CSV output and types header"""

        # test the MMPObjectClass using above temp file, then write to new output
        self.test_mmp_object.build_from_dicer(self.temp_file_input_smi.name, 'SINGLE', 'REMOVE_NONRINGS')
        self.test_mmp_object.print_to_file(self.temp_file_output_pairs.name, 'SINGLE', inc_types_header=True)

        test_results_filehandle = open(self.temp_file_output_pairs.name, 'r')
        for line in test_results_filehandle:
            line = line.rstrip('\r')
            line = line.rstrip('\n')
            self.test_dataset_testresults[line] = None

        #print(self.test_dataset_testresults) # use this pprint statement to regenerate the golden data
        self.assertEqual(self.test_dataset_testresults, self.test_dataset_goldenoutput_pairs_04)

    def test_inspector_double_cut_pairs(self):

        """Test the generation of single cut pairs with CSV output and types header"""

        self.test_mmp_object.build_from_dicer(self.temp_file_input_smi.name, 'DOUBLE', 'NONE')

        self.test_mmp_object._inspector_double_pairs_dict()

if __name__ == '__main__':
    unittest.main()
